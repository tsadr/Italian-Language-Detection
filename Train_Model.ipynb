{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04b1b92-c8a5-4934-baa6-e4704ce37aa7",
   "metadata": {},
   "source": [
    "First, let's import the necessary libraries and load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2f06e7-9ac2-4c88-a9ff-f896b8e91443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 13:11:29.340473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-09 13:11:30.593842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-09 13:11:30.593969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-04-09 13:11:30.593990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import save_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d4347-3725-47fb-a3fc-eeb57faa3769",
   "metadata": {},
   "source": [
    "Next, we need to preprocess the data by converting the text into numerical sequences that can be fed into the model. We'll use the Tokenizer class from Keras to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f814c4-7de6-4f87-bf86-447c06d8c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('Language Detection.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57659e46-d9b5-41f6-80b1-f85ef2aac85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10337 entries, 0 to 10336\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      10337 non-null  object\n",
      " 1   Language  10337 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 161.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca6aaa4-3305-45f8-9fd3-272151a23233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10337</td>\n",
       "      <td>10337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10267</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Jag är ledsen.</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Text Language\n",
       "count            10337    10337\n",
       "unique           10267       17\n",
       "top     Jag är ledsen.  English\n",
       "freq                 3     1385"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb05fae1-6266-4ecb-a87f-57317d483499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.05562542323692"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374490db-3214-4c64-ba81-ba7d9a1d1d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text to numerical sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['Text'])\n",
    "\n",
    "X = tokenizer.texts_to_sequences(data['Text'])\n",
    "X = pad_sequences(X, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f4721e-39e0-483e-863b-5e50066d07a1",
   "metadata": {},
   "source": [
    "We also need to one-hot encode the labels (which are currently in string format) to numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b72a0a3-40a5-4b32-8b60-06e2f02d2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "labels = pd.get_dummies(data['Language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7434602c-57dd-4014-9cdb-eece986625ef",
   "metadata": {},
   "source": [
    "Now, we can split the data into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3673d499-8b0f-4edd-9dc9-f8a5157d5223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels['Italian'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2024b-bed8-40b2-aee8-7a24fc1059bc",
   "metadata": {},
   "source": [
    "We'll use a simple LSTM model with an embedding layer and a few dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20274c44-44bd-408c-bdd4-c7d27f0c8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 13:11:35.202365: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=100))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c9caed-77a3-4679-b02c-d824b3969621",
   "metadata": {},
   "source": [
    "Finally, we can train the model and evaluate its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4464b05c-e436-4824-a1e7-d3730b63a9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/engine/data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "207/207 [==============================] - 47s 206ms/step - loss: 0.2893 - accuracy: 0.9321 - val_loss: 0.2526 - val_accuracy: 0.9305\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 19s 93ms/step - loss: 0.2635 - accuracy: 0.9339 - val_loss: 0.1455 - val_accuracy: 0.9305\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 13s 60ms/step - loss: 0.1536 - accuracy: 0.9317 - val_loss: 0.1334 - val_accuracy: 0.9305\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 12s 58ms/step - loss: 0.1466 - accuracy: 0.9320 - val_loss: 0.1327 - val_accuracy: 0.9305\n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 9s 43ms/step - loss: 0.1394 - accuracy: 0.9320 - val_loss: 0.1320 - val_accuracy: 0.9305\n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 7s 35ms/step - loss: 0.1386 - accuracy: 0.9348 - val_loss: 0.1313 - val_accuracy: 0.9353\n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 6s 30ms/step - loss: 0.1388 - accuracy: 0.9394 - val_loss: 0.1260 - val_accuracy: 0.9426\n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 6s 27ms/step - loss: 0.1326 - accuracy: 0.9457 - val_loss: 0.1238 - val_accuracy: 0.9450\n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 6s 27ms/step - loss: 0.1256 - accuracy: 0.9472 - val_loss: 0.1180 - val_accuracy: 0.9504\n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 5s 25ms/step - loss: 0.1233 - accuracy: 0.9486 - val_loss: 0.1135 - val_accuracy: 0.9553\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1149 - accuracy: 0.9550\n",
      "Test loss: 0.11488939076662064, Test accuracy: 0.9550290107727051\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c4dd9-c8b7-4c6a-beda-f8afa771e111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  4/207 [..............................] - ETA: 4s - loss: 0.0752 - accuracy: 0.9609"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/engine/data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 5s 26ms/step - loss: 0.1243 - accuracy: 0.9530 - val_loss: 0.1077 - val_accuracy: 0.9589\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 6s 27ms/step - loss: 0.1200 - accuracy: 0.9554 - val_loss: 0.1057 - val_accuracy: 0.9559\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 4s 21ms/step - loss: 0.1215 - accuracy: 0.9559 - val_loss: 0.0977 - val_accuracy: 0.9674\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 6s 27ms/step - loss: 0.1166 - accuracy: 0.9534 - val_loss: 0.0980 - val_accuracy: 0.9692\n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 5s 25ms/step - loss: 0.1169 - accuracy: 0.9575 - val_loss: 0.0951 - val_accuracy: 0.9686\n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 6s 28ms/step - loss: 0.1107 - accuracy: 0.9660 - val_loss: 0.0893 - val_accuracy: 0.9704\n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 5s 24ms/step - loss: 0.1033 - accuracy: 0.9702 - val_loss: 0.0903 - val_accuracy: 0.9680\n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 5s 26ms/step - loss: 0.1042 - accuracy: 0.9699 - val_loss: 0.0892 - val_accuracy: 0.9698\n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 5s 24ms/step - loss: 0.0993 - accuracy: 0.9710 - val_loss: 0.0854 - val_accuracy: 0.9740\n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 5s 24ms/step - loss: 0.1007 - accuracy: 0.9719 - val_loss: 0.0831 - val_accuracy: 0.9764\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "#loss, accuracy = model.evaluate(X_test, y_test)\n",
    "#print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "825ca7ec-a77d-4801-82ca-eab2399f8c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/207 [..............................] - ETA: 8s - loss: 0.0365 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/engine/data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 5s 23ms/step - loss: 0.0974 - accuracy: 0.9729 - val_loss: 0.0819 - val_accuracy: 0.9746\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 5s 24ms/step - loss: 0.0951 - accuracy: 0.9728 - val_loss: 0.0817 - val_accuracy: 0.9758\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 4s 21ms/step - loss: 0.0936 - accuracy: 0.9732 - val_loss: 0.0767 - val_accuracy: 0.9770\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 5s 22ms/step - loss: 0.0941 - accuracy: 0.9743 - val_loss: 0.0776 - val_accuracy: 0.9776\n",
      "Epoch 5/10\n",
      "207/207 [==============================] - 5s 22ms/step - loss: 0.0899 - accuracy: 0.9754 - val_loss: 0.0762 - val_accuracy: 0.9782\n",
      "Epoch 6/10\n",
      "207/207 [==============================] - 5s 26ms/step - loss: 0.0887 - accuracy: 0.9779 - val_loss: 0.0738 - val_accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "207/207 [==============================] - 5s 24ms/step - loss: 0.0888 - accuracy: 0.9767 - val_loss: 0.0837 - val_accuracy: 0.9794\n",
      "Epoch 8/10\n",
      "207/207 [==============================] - 5s 23ms/step - loss: 0.0836 - accuracy: 0.9779 - val_loss: 0.0825 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "207/207 [==============================] - 5s 26ms/step - loss: 0.0829 - accuracy: 0.9779 - val_loss: 0.0821 - val_accuracy: 0.9770\n",
      "Epoch 10/10\n",
      "207/207 [==============================] - 6s 28ms/step - loss: 0.0874 - accuracy: 0.9767 - val_loss: 0.0788 - val_accuracy: 0.9776\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.1036 - accuracy: 0.9705\n",
      "Test loss: 0.10357607901096344, Test accuracy: 0.9705029129981995\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {loss}, Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680462c-a499-4f91-991d-687e90e88c75",
   "metadata": {},
   "source": [
    "We will now save the model for future inference use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8755a1b7-6dcc-47de-a6e7-ebde6aec7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a24c9a-432e-4000-893f-25fc5bb294ab",
   "metadata": {},
   "source": [
    "We have now loaded our model to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1807734f-0098-457c-a6e2-f2c75687f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94906d5-62d9-450b-bf35-a0ab8a14113e",
   "metadata": {},
   "source": [
    "If the probability of the prediction is higher than 0.5, we label the sentence as Italian. Otherwise, we label it as not Italian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79de1985-e9b0-4628-99d7-d8cdcbd6ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "[[0.78383523]]\n"
     ]
    }
   ],
   "source": [
    "# Define a sentence to test\n",
    "sentence = \"Io sono una casalinga che lavora inoltre a casa come articolista. Mio marito è invece un operaio.\"\n",
    "# Convert the sentence to a numerical sequence using the tokenizer\n",
    "x_test = tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "# Pad the sequence so it has the same length as the training sequences\n",
    "x_test = pad_sequences(x_test, maxlen=100, padding='post')\n",
    "\n",
    "# Make a prediction using the model\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "# Print the predicted value\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
